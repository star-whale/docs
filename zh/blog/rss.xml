<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Starwhale Blog</title>
        <link>https://doc.starwhale.ai/zh/blog</link>
        <description>Starwhale Blog</description>
        <lastBuildDate>Mon, 11 Sep 2023 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>zh</language>
        <item>
            <title><![CDATA[如何复现评测结果]]></title>
            <link>https://doc.starwhale.ai/zh/blog/reproduce-and-compare-evals</link>
            <guid>https://doc.starwhale.ai/zh/blog/reproduce-and-compare-evals</guid>
            <pubDate>Mon, 11 Sep 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[评测结果复现]]></description>
            <content:encoded><![CDATA[<p>对<a href="https://cloud.starwhale.cn/simple/report/preview/?rid=e9067622-fec2-4701-a960-eb142a54ff94" target="_blank" rel="noopener noreferrer">Starwhale的开源大语言模型评测报告</a>的评测结果或其他人的评测结果存疑，应该如何复现和对比评测结果？下文将为大家逐一讲解说明</p><p><strong>基本流程</strong>：登录账号 → 创建项目 → 运行评测 → 对比结果</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="step1登录账号">STEP1：登录账号<a href="#step1登录账号" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>需要登录Starwhale平台，点击跳转<a href="https://cloud.starwhale.cn/login?lang=zh" target="_blank" rel="noopener noreferrer">登录入口</a>。如您尚未注册，可点击 <a href="https://cloud.starwhale.cn/signup" target="_blank" rel="noopener noreferrer">注册入口</a> 进行注册。</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="step2创建项目">STEP2：创建项目<a href="#step2创建项目" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>成功登录后进入项目列表页，点击右上角的 <strong>创建</strong> 项目按钮，输入项目名称,点击 <strong>提交</strong> 按钮即可新建一个项目。</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="step3运行评测">STEP3：运行评测<a href="#step3运行评测" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>进入<strong>评测</strong>列表页，点击右上角的 <strong>创建</strong> 评测按钮，并选择相应参数。</p><p>例如想复现baichuan2-13b使用cmmlu数据集评测的结果，可参考以下内容进行操作：</p><ol><li>选择运行资源，推荐选择资源：A10<!-- -->*<!-- -->24G<!-- -->*<!-- -->2；</li><li>选择模型：starwhale/llm-leaderboard/baichuan2-13b/atgoiscm(v1、latest)；</li><li>选择handler：选择：src.evaluation:evaluation_results；</li><li>选择数据集：starwhale/llm-leaderboard/cmmlu/kiwtxza7(v1、latest)；</li><li>选择运行时：starwhale/llm-leaderboard/llm-leaderboard/ickinf6q(v1、latest)；</li><li>高级配置，关闭自动释放</li></ol><p>点击 <strong>提交</strong> 即可运行评测。评测运行时，可在评测详情页的<strong>任务TAB页</strong>点击 <strong>查看日志</strong> 了解评测运行情况；当评测状态为“成功”时，可在列表页和详情页查看评测结果。</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="step4对比结果">STEP4：对比结果<a href="#step4对比结果" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>进入<strong>报告</strong>列表页，点击右上角的 <strong>创建</strong> 报告按钮。</p><p>报告提供富文本编辑能力，这里主要介绍如何将自己的评测结果和 Starwhale 或者其他的评测结果进行对比。</p><ol><li>输入 报告标题、描述；</li><li>输入 <strong>/</strong> ，选择 <strong>Panel</strong> 选项；</li><li>点击 <strong>添加评测</strong> 按钮，选择评测所属的项目，如“llm-leaderboard”，然后勾选想要添加的评测，点击 <strong>添加</strong> 可将评测加入评测列表。支持跨项目添加评测，您可以添加多个您想对比的评测；</li><li>将想要进行对比的评测添加完成后：可点击 <strong>列管理</strong> 设置图标设置评测列表展示的字段及字段展示顺序；鼠标hover评测列表字段，可固定该列、或者按照升序降序进行排序；</li><li>可点击 <strong>添加图表</strong> 按钮 ：选择图表类型，如 Bar Chart；添加 Metrics，如 accuracy相关指标（支持指标模糊搜索）；输入 图表标题（非必填），点击 <strong>提交</strong> 即可将数据以条形图的方式展示，以便更直观得分析；</li><li>点击 <strong>发布到项目</strong> 按钮发布报告；</li><li>如想分享给其他人，进入 <strong>报告列表页</strong> ，打开 <strong>分享</strong> 开关，获得报告链接的人即可浏览报告。</li></ol><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/Blog/reproduce-and-compare-evals.gif" alt="reproduce and compare evals" class="img_ev3q"></p><p>以上就是关于如何使用 Starwhale Cloud 复现和对比评测结果的说明，如果您在使用过程中有任何问题欢迎私信留言。您也可以通过<a href="https://starwhale.cn/" target="_blank" rel="noopener noreferrer">Starwhale官网</a>了解更多信息，感谢您的关注和支持。</p>]]></content:encoded>
            <category>模型</category>
            <category>模型评测</category>
        </item>
        <item>
            <title><![CDATA[5分钟快速运行Llama 2-Chat]]></title>
            <link>https://doc.starwhale.ai/zh/blog/run-llama2-chat-in-five-minutes</link>
            <guid>https://doc.starwhale.ai/zh/blog/run-llama2-chat-in-five-minutes</guid>
            <pubDate>Mon, 24 Jul 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[5分钟快速运行Llama 2-Chat]]></description>
            <content:encoded><![CDATA[<p>Meta Llama 2 一经发布就吸引了全世界的目光，<a href="https://starwhale.cn/" target="_blank" rel="noopener noreferrer">Starwhale</a> 特别制作了 Llama 2-Chat 和 Llama 2-7b模型包。只需5分钟，您就可以在 <a href="https://cloud.starwhale.cn" target="_blank" rel="noopener noreferrer">https://cloud.starwhale.cn</a> 上和 Llama 2-Chat 进行对话。</p><p>后续我们也将提供Llama 2-13b 和 Llama 2-70b 的模型包，感兴趣的朋友们请持续关注！</p><p>下文将为大家详细介绍什么是 Llama 2，什么是 Starwhale 以及如何使用 Starwhale 运行 Llama 2-Chat。</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="什么是-llama-2">什么是 Llama 2<a href="#什么是-llama-2" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h2><p>Llama 2 系列模型是一组使用了优化的自回归 Transformer 架构的大语言模型，经过了预训练和微调，包含70亿、130亿和700亿三种参数版本。此外，Meta还训练了 340亿参数版本，但并未发布，相关数据在论文中有体现。</p><p>预训练：相比 Llama 1, Llama 2 的训练数据多了40%，用了2万亿个tokens进行训练，而且上下文长度是 Llama 1 的两倍，达到4096。Llama 2 适合用于各种自然语言生成任务。</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/cmp1-2.png" alt="image" class="img_ev3q"></p><p>Meta将 Llama 2-70b 的结果与闭源模型进行了比较，在 MMLU 和 GSM8K 上的表现接近 GPT-3.5, 但在编码基准上存在显著差异。此外，几乎所有基准上， Llama 2-70b 的结果与谷歌 PaLM-540 b 持平或表现更好，与 GPT-4 和 PaLM-2-L 的性能仍存在较大差距。</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/evaluation.png" alt="image" class="img_ev3q"></p><p>微调：Llama 2-Chat 是基于Llama 2 针对聊天对话场景微调的版本，使用 SFT (监督微调) 和 RLHF (人类反馈强化学习)进行迭代优化，以便更好的和人类偏好保持一致，提高安全性。微调数据使用了包括公开可用的指令数据集，以及一百多万新的人工标注样本。Llama 2-Chat 可用于类似助理的聊天。下图展示了单轮和多轮对话的违规百分比，与基线相比，Llama 2-Chat 在多轮对话中表现尤其良好。</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/voliation.png" alt="image" class="img_ev3q"></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="什么是-starwhale">什么是 Starwhale<a href="#什么是-starwhale" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h2><p>Starwhale是一个MLOps平台，提供MLOps全流程解决方案，能够让开发者和企业高效便捷地进行模型托管、运行、评测、部署及数据集管理等。用户可以根据自己的需要，选择 Standalone、Server 或者 Cloud 任意一版使用，详细说明可参考文档<a href="https://starwhale.cn/docs/" target="_blank" rel="noopener noreferrer">什么是Starwhale</a>。</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="如何使用-starwhale-cloud-运行-llama-2-chat">如何使用 Starwhale Cloud 运行 Llama 2-Chat<a href="#如何使用-starwhale-cloud-运行-llama-2-chat" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h2><p>基本流程：登录账号 → 创建项目 → 运行模型 → 进行对话</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="一-登录"><strong>一. 登录</strong><a href="#一-登录" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>首先，需要登录Starwhale平台，点击跳转<a href="https://cloud.starwhale.cn/login?lang=zh" target="_blank" rel="noopener noreferrer">登录入口</a>。如您尚未注册，可点击 <a href="https://cloud.starwhale.cn/signup" target="_blank" rel="noopener noreferrer">注册入口</a> 进行注册。</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="二-创建项目"><strong>二. 创建项目</strong><a href="#二-创建项目" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>成功登录后进入项目列表页，点击右上角的<strong>创建</strong>项目按钮，输入项目名称,点击 提交 按钮即可新建一个项目。</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/project-list.png" alt="image" class="img_ev3q"></p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/project-create.png" alt="image" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="三-运行模型"><strong>三. 运行模型</strong><a href="#三-运行模型" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h3><p>进入作业列表页，点击右上角的<strong>创建</strong>任务按钮。</p><p> 1) 选择运行资源，可以选择 A100 80G<em>1（推荐） 或者 A10 24G</em>1
2) 选择模型：starwhale/public/llama2-7b-chat/ki72ulaf(latest)
3) 选择handler：运行对话模型，选择默认项：evaluation:chatbot
4) 选择运行时：选择默认项，内置
5) 高级配置，打开自动释放开关：可设置任务自动释放时长，达到设置时长，系统会自动取消任务运行。如不设置自动释放，您可以在体验完成后手动取消任务。</p><p>点击<strong>提交</strong>即可运行模型</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/evaluation-create.png" alt="image" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="四-查看运行结果和日志"><strong>四. 查看运行结果和日志</strong><a href="#四-查看运行结果和日志" class="hash-link" aria-label="标题的直接链接" title="标题的直接链接">​</a></h4><p>作业列表页可以查看项目中的所有作业。</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/job-list.png" alt="image" class="img_ev3q"></p><p>点击<strong>作业ID</strong> ，进入任务详情页，点击<strong>查看日志</strong>可查看</p><p>从任务提交到模型运行起来，总计用时5分04秒</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/log.png" alt="image" class="img_ev3q"></p><p>运行成功后返回任务列表，点击<strong>终端</strong>按钮，可打开 chatbox 页面，在 chatbox 页面和 Llama 2-Chat 对话</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/job-list.png" alt="image" class="img_ev3q"></p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/chatbot.png" alt="image" class="img_ev3q"></p><p>以上就是关于如何使用 Starwhale Cloud 运行 Llama 2-Chat 的说明，如果您在使用过程中有任何问题欢迎私信留言。您也可以通过<a href="https://starwhale.cn/" target="_blank" rel="noopener noreferrer">Starwhale官网</a>了解更多信息，感谢您的关注和支持。</p>]]></content:encoded>
            <category>模型</category>
            <category>llama2</category>
        </item>
        <item>
            <title><![CDATA[Starwhale是什么？]]></title>
            <link>https://doc.starwhale.ai/zh/blog/intro-starwhale</link>
            <guid>https://doc.starwhale.ai/zh/blog/intro-starwhale</guid>
            <pubDate>Fri, 21 Jul 2023 00:00:00 GMT</pubDate>
            <description><![CDATA[Starwhale介绍]]></description>
            <content:encoded><![CDATA[<p>Starwhale是一个 MLOps平台，能够让您的模型创建、评估和发布流程变得更加轻松。 它旨在为数据科学家和机器学习工程师创建一个方便的工具。</p><p>Starwhale帮您:</p><ul><li>跟踪您的训练/测试数据历史记录，包括所有数据项及其相关标签，以便您轻松访问它们。</li><li>管理您可以在团队中共享的模型包。</li><li>在不同的环境中运行您的模型，无论是在 Nvidia GPU 服务器上还是在嵌入式设备（如 Cherry Pi）上。</li><li>为您的模型快速创建配备交互式 Web UI的在线服务。</li></ul><p>Starwhale是一个开放的平台，您可以创建插件来满足自己的需求。</p>]]></content:encoded>
            <category>intro</category>
        </item>
    </channel>
</rss>
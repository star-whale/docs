"use strict";(self.webpackChunkstarwhale_docs=self.webpackChunkstarwhale_docs||[]).push([[5286],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>u});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function r(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),d=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=d(e.components);return n.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,l=e.originalType,s=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),m=d(a),u=i,h=m["".concat(s,".").concat(u)]||m[u]||c[u]||l;return a?n.createElement(h,o(o({ref:t},p),{},{components:a})):n.createElement(h,o({ref:t},p))}));function u(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var l=a.length,o=new Array(l);o[0]=m;var r={};for(var s in t)hasOwnProperty.call(t,s)&&(r[s]=t[s]);r.originalType=e,r.mdxType="string"==typeof e?e:i,o[1]=r;for(var d=2;d<l;d++)o[d]=a[d];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},49681:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>c,frontMatter:()=>l,metadata:()=>r,toc:()=>d});var n=a(83117),i=(a(67294),a(3905));const l={title:"Dataset Building"},o=void 0,r={unversionedId:"dataset/build",id:"version-0.6.12/dataset/build",title:"Dataset Building",description:"Starwhale provides a highly flexible method to build datasets, allowing you to build dataset from various file types including images, audio, video, CSV, JSON, and JSONL files. Python scripts and datasets from the Huggingface Hub can also be used for construction.",source:"@site/versioned_docs/version-0.6.12/dataset/build.md",sourceDirName:"dataset",slug:"/dataset/build",permalink:"/dataset/build",draft:!1,editUrl:"https://github.com/star-whale/docs/tree/main/versioned_docs/version-0.6.12/dataset/build.md",tags:[],version:"0.6.12",frontMatter:{title:"Dataset Building"},sidebar:"mainSidebar",previous:{title:"The dataset.yaml Specification",permalink:"/dataset/yaml"},next:{title:"Dataset Loading",permalink:"/dataset/load"}},s={},d=[{value:"Building from Data Files",id:"building-from-data-files",level:2},{value:"Image",id:"image",level:3},{value:"Video",id:"video",level:3},{value:"Audio",id:"audio",level:3},{value:"csv Files",id:"csv-files",level:3},{value:"json/jsonl Files",id:"jsonjsonl-files",level:3},{value:"Building from Huggingface Hub",id:"building-from-huggingface-hub",level:2},{value:"Building from Python SDK scripts",id:"building-from-python-sdk-scripts",level:2},{value:"Dataset Initialization",id:"dataset-initialization",level:3},{value:"Adding and Updating Dataset Elements",id:"adding-and-updating-dataset-elements",level:3},{value:"The append Method",id:"the-append-method",level:4},{value:"__setitem__ Method",id:"__setitem__-method",level:4},{value:"Building from Python Handler",id:"building-from-python-handler",level:2}],p={toc:d};function c(e){let{components:t,...a}=e;return(0,i.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"Starwhale provides a highly flexible method to build datasets, allowing you to build dataset from various file types including images, audio, video, CSV, JSON, and JSONL files. Python scripts and datasets from the Huggingface Hub can also be used for construction."),(0,i.kt)("h2",{id:"building-from-data-files"},"Building from Data Files"),(0,i.kt)("h3",{id:"image"},"Image"),(0,i.kt)("p",null,"Starwhale supports recursively traversing image files within directories to build a dataset without any coding:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Supported image formats: ",(0,i.kt)("inlineCode",{parentName:"li"},"png"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"jpg"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"jpeg"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"webp"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"svg"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"apng"),"."),(0,i.kt)("li",{parentName:"ul"},"Images are converted to ",(0,i.kt)("inlineCode",{parentName:"li"},"Starwhale.Image")," type and can be viewed in the Starwhale Server Web page."),(0,i.kt)("li",{parentName:"ul"},"Supported by ",(0,i.kt)("inlineCode",{parentName:"li"},"swcli dataset build --image")," command line and ",(0,i.kt)("inlineCode",{parentName:"li"},"starwhale.Dataset.from_folder")," Python SDK."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Label mechanism"),": when SDK sets ",(0,i.kt)("inlineCode",{parentName:"li"},"auto_label=True")," or command line sets ",(0,i.kt)("inlineCode",{parentName:"li"},"--auto-label"),", the parent directory name will be used as the ",(0,i.kt)("inlineCode",{parentName:"li"},"label"),"."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Metadata mechanism"),": dataset columns can be expanded by setting ",(0,i.kt)("inlineCode",{parentName:"li"},"metadata.csv")," or ",(0,i.kt)("inlineCode",{parentName:"li"},"metadata.jsonl")," files in the root directory."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Caption mechanism"),": when ",(0,i.kt)("inlineCode",{parentName:"li"},"{image-name}.txt")," files are found in the same directory, the content will be automatically imported and populated into the ",(0,i.kt)("inlineCode",{parentName:"li"},"caption")," column.")),(0,i.kt)("p",null,"Assuming there are the following four files in the folder directory:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"folder/dog/1.png\nfolder/cat/2.png\nfolder/dog/3.png\nfolder/cat/4.png\n")),(0,i.kt)("p",null,"Command line construction:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"\u276f swcli dataset build --image folder --name image-folder\n\ud83d\udea7 start to build dataset bundle...\n\ud83d\udc77 uri local/project/self/dataset/image-folder/version/latest\n\ud83c\udf0a creating dataset local/project/self/dataset/image-folder/version/uw6mdisnf7alg4t4fs2myfug4ie4636w3x4jqcu2...\n\ud83e\udd8b update 4 records into dataset\n\ud83c\udf3a congratulation! you can run  swcli dataset info image-folder/version/uw6mdisnf7al\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"\u276f swcli dataset head image-folder -n 2\nrow  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83c\udf33 id: cat/2.png\n\ud83c\udf00 features:\n         \ud83d\udd05 file_name : cat/2.png\n         \ud83d\udd05 label : cat\n         \ud83d\udd05 file : ArtifactType.Image, display:2.png, mime_type:MIMEType.PNG, shape:[None, None, 3], encoding:\nrow  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83c\udf33 id: cat/4.png\n\ud83c\udf00 features:\n         \ud83d\udd05 file_name : cat/4.png\n         \ud83d\udd05 label : cat\n         \ud83d\udd05 file : ArtifactType.Image, display:4.png, mime_type:MIMEType.PNG, shape:[None, None, 3], encoding:\n")),(0,i.kt)("p",null,"Python SDK construction:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import Dataset\nds = Dataset.from_folder("folder", kind="image")\nprint(ds)\nprint(ds.fetch_one().features)\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"\ud83c\udf0a creating dataset local/project/self/dataset/folder/version/nyc2ay4gnyayv4zqalovdgakl3k2esvrne42cjna...\n\ud83e\udd8b update 4 records into dataset\nDataset: folder, stash version: d22hdiwyakdfh5xitcpn2s32gblfbhrerzczkb63, loading version: nyc2ay4gnyayv4zqalovdgakl3k2esvrne42cjna\n{'file_name': 'cat/2.png', 'label': 'cat', 'file': ArtifactType.Image, display:2.png, mime_type:MIMEType.PNG, shape:[None, None, 3], encoding: }\n")),(0,i.kt)("h3",{id:"video"},"Video"),(0,i.kt)("p",null,"Recursive traversal of video files in a directory to construct Starwhale datasets without any coding:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Supported video formats: ",(0,i.kt)("inlineCode",{parentName:"li"},"mp4"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"webm")," and ",(0,i.kt)("inlineCode",{parentName:"li"},"avi"),"."),(0,i.kt)("li",{parentName:"ul"},"Videos are converted to Starwhale.Video types and can be viewed in the Starwhale Server Web page."),(0,i.kt)("li",{parentName:"ul"},"Supported by ",(0,i.kt)("inlineCode",{parentName:"li"},"swcli dataset build --video")," command line and ",(0,i.kt)("inlineCode",{parentName:"li"},"starwhale.Dataset.from_folder")," Python SDK."),(0,i.kt)("li",{parentName:"ul"},"Label, caption and metadata mechanisms are the same as for images.")),(0,i.kt)("h3",{id:"audio"},"Audio"),(0,i.kt)("p",null,"Recursive traversal of audio files in a directory to construct Starwhale datasets without any coding:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Supported audio formats: ",(0,i.kt)("inlineCode",{parentName:"li"},"mp3")," and ",(0,i.kt)("inlineCode",{parentName:"li"},"wav"),"."),(0,i.kt)("li",{parentName:"ul"},"Audio is converted to Starwhale.Audio types and can be viewed in the Starwhale Server Web page."),(0,i.kt)("li",{parentName:"ul"},"Supported by ",(0,i.kt)("inlineCode",{parentName:"li"},"swcli dataset build --audio")," command line and ",(0,i.kt)("inlineCode",{parentName:"li"},"starwhale.Dataset.from_folder")," Python SDK."),(0,i.kt)("li",{parentName:"ul"},"Label, caption and metadata mechanisms are the same as for images.")),(0,i.kt)("h3",{id:"csv-files"},"csv Files"),(0,i.kt)("p",null,"Command line or Python SDK can directly convert local or remote csv files into Starwhale datasets:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Support one or more local csv files."),(0,i.kt)("li",{parentName:"ul"},"Support recursive finding of csv files in a local directory."),(0,i.kt)("li",{parentName:"ul"},"Support one or more remote csv files specified by http urls.")),(0,i.kt)("p",null,"Command line construction:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"\u276f swcli dataset build --name product-desc-modelscope --csv https://modelscope.cn/api/v1/datasets/lcl193798/product_description_generation/repo\\?Revision\\=master\\&FilePath\\=test.csv --encoding=utf-8-sig\n\ud83d\udea7 start to build dataset bundle...\n\ud83d\udc77 uri local/project/self/dataset/product-desc-modelscope/version/latest\n\ud83c\udf0a creating dataset local/project/self/dataset/product-desc-modelscope/version/wzaz4ccodpyj4jelgupljreyida2bleg5xp7viwe...\n\ud83e\udd8b update 3848 records into dataset\n\ud83c\udf3a congratulation! dataset build from csv files(('https://modelscope.cn/api/v1/datasets/lcl193798/product_description_generation/repo?Revision=master&FilePath=test.csv',)) has been built. You can run  swcli dataset info product-desc-modelscope/version/wzaz4ccodpyj\n")),(0,i.kt)("p",null,"Python SDK construction:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import Dataset\nds = Dataset.from_csv(path="http://example.com/data.csv", name="my-csv-dataset")\n')),(0,i.kt)("h3",{id:"jsonjsonl-files"},"json/jsonl Files"),(0,i.kt)("p",null,"Command line or Python SDK can directly convert local or remote json/jsonl files into Starwhale datasets:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Support one or more local json/jsonl files."),(0,i.kt)("li",{parentName:"ul"},"Support recursive finding of json/jsonl files in a local directory."),(0,i.kt)("li",{parentName:"ul"},"Support one or more remote json/jsonl files specified by http urls.")),(0,i.kt)("p",null,"For JSON files:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"By default, the parsed json object is assumed to be a list, and each object in the list is a dict, which maps to one row in the Starwhale dataset."),(0,i.kt)("li",{parentName:"ul"},"The ",(0,i.kt)("inlineCode",{parentName:"li"},"--field-selector")," or ",(0,i.kt)("inlineCode",{parentName:"li"},"field_selector")," parameter can be used to locate a specific list.")),(0,i.kt)("p",null,"For example, for the json file:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "p1": {\n     "p2":{\n       "p3": [\n         {"a": 1, "b": 2},\n         {"a": 10, "b": 20}\n       ]\n     }\n  }\n}\n')),(0,i.kt)("p",null,"Set ",(0,i.kt)("inlineCode",{parentName:"p"},"--field-selector=p1.p2.p3")," to accurately add two rows of data to the dataset."),(0,i.kt)("p",null,"Command line construction:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"\u276f swcli dataset build --json https://modelscope.cn/api/v1/datasets/damo/100PoisonMpts/repo\\?Revision\\=master\\&FilePath\\=train.jsonl\n\ud83d\udea7 start to build dataset bundle...\n\ud83d\udc77 uri local/project/self/dataset/json-b0o2zsvg/version/latest\n\ud83c\udf0a creating dataset local/project/self/dataset/json-b0o2zsvg/version/q3uoziwqligxdggncqywpund75jz55h3bne6a5la...\n\ud83e\udd8b update 906 records into dataset\n\ud83c\udf3a congratulation! dataset build from ('https://modelscope.cn/api/v1/datasets/damo/100PoisonMpts/repo?Revision=master&FilePath=train.jsonl',) has been built. You can run  swcli dataset info json-b0o2zsvg/version/q3uoziwqligx\n")),(0,i.kt)("p",null,"Python SDK construction:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import Dataset\nmyds = Dataset.from_json(\n   name="translation",\n   text=\'{"content": {"child_content": [{"en":"hello","zh-cn":"\u4f60\u597d"},{"en":"how are you","zh-cn":"\u6700\u8fd1\u600e\u4e48\u6837"}]}}\',\n   field_selector="content.child_content"\n)\nprint(myds[0].features["zh-cn"])\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"\ud83c\udf0a creating dataset local/project/self/dataset/translation/version/kblfn5zh4cpoqxqbhgdfbvonulr2zefp6lojq44y...\n\ud83e\udd8b update 2 records into dataset\n\u4f60\u597d\n")),(0,i.kt)("h2",{id:"building-from-huggingface-hub"},"Building from Huggingface Hub"),(0,i.kt)("p",null,"There are numerous datasets available on the Huggingface Hub, which can be converted into Starwhale Dataset with a single line of code or command."),(0,i.kt)("admonition",{type:"tip"},(0,i.kt)("p",{parentName:"admonition"},"Huggingface Datasets conversion relies on the ",(0,i.kt)("a",{parentName:"p",href:"https://pypi.org/project/datasets/"},"datasets")," library.")),(0,i.kt)("p",null,"Command line:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"swcli dataset build -hf lambdalabs/pokemon-blip-captions --name pokemon\n")),(0,i.kt)("p",null,"Python SDK:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import Dataset\n\n# You only specify starwhale dataset expected name and huggingface repo name\n# example: https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions\nds = Dataset.from_huggingface("pokemon", "lambdalabs/pokemon-blip-captions")\nprint(ds)\nprint(len(ds))\nprint(repr(ds.fetch_one()))\n')),(0,i.kt)("h2",{id:"building-from-python-sdk-scripts"},"Building from Python SDK scripts"),(0,i.kt)("p",null,"The Starwhale Dataset SDK provides a way similar to Python ",(0,i.kt)("inlineCode",{parentName:"p"},"dict")," to add or update data, enabling the creation and update of local or remote datasets."),(0,i.kt)("p",null,"Starwhale defines two attributes for each row of data: ",(0,i.kt)("inlineCode",{parentName:"p"},"key")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"features"),"."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"key"),": int or str type. There is only one type of ",(0,i.kt)("inlineCode",{parentName:"li"},"key")," in a dataset. ",(0,i.kt)("inlineCode",{parentName:"li"},"key")," indicates the unique index of that row of data."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"features"),": dict type. Starwhale Dataset adopts a schema-free design, so the ",(0,i.kt)("inlineCode",{parentName:"li"},"features")," structure of each row can be different.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"features")," data supports Python constant types like int, float, str, as well as Starwhale types like Image, Video, Audio, Text, and Binary. It also supports Python compound types like list, tuple, dict.")))),(0,i.kt)("h3",{id:"dataset-initialization"},"Dataset Initialization"),(0,i.kt)("p",null,"To create, update, or load a dataset, you need to get a ",(0,i.kt)("inlineCode",{parentName:"p"},"Starwhale.Dataset")," object, usually in the following ways:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import dataset\n\n# Create a dataset named new-test in standalone instance. If it exists, raise an exception.\nlocal_ds = dataset("new-test", create="empty")\nprint(local_ds)\nprint(len(local_ds))\n\n# If the mnist64 dataset does not exist, create one; otherwise, load this existing dataset.\nremote_ds = dataset("https://cloud.starwhale.cn/project/starwhale:helloworld/dataset/mnist64", create="auto")\nprint(remote_ds)\nprint(len(remote_ds))\n\n# Load the existing dataset named mnist64, and if it does not exist, an error will be raised.\nexisted_ds = dataset("mnist64", create="forbid")\nprint(existed_ds)\nprint(len(existed_ds))\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"Dataset: new-test, stash version: y4touw3btifhkd4f2gg4x3qvydgnfmvoztqqm5cf, loading version: y4touw3btifhkd4f2gg4x3qvydgnfmvoztqqm5cf\n0\n\nDataset: mnist64, stash version: 4z5wpbpozsxlelma3j6soeatekufymnyxdeihoqo, loading version: vs3gnaauakidjcc5effevaoh63vivu7dzodo5cmc\n500\n\nDataset: mnist64, stash version: 3ahtfbizw63myxcz34ebd72lhgc25dualcmtznts, loading version: lwhvvixpimlsghfs2xqmtgrwti4yn2z5nevz7hth\n500\n")),(0,i.kt)("h3",{id:"adding-and-updating-dataset-elements"},"Adding and Updating Dataset Elements"),(0,i.kt)("p",null,"After adding data, calling ",(0,i.kt)("inlineCode",{parentName:"p"},"commit")," will generate a new version that can then be used to access the dataset."),(0,i.kt)("h4",{id:"the-append-method"},"The append Method"),(0,i.kt)("p",null,"The Dataset provides the append function, which automatically adds ",(0,i.kt)("inlineCode",{parentName:"p"},"features")," to a new row in the dataset when called."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import dataset\nds = dataset("new-test", create="empty")\n\n# key is the auto increment index. The example key is zero.\nds.append({"a": 0, "b": 0})\n\n# Keys in the dataset can also be explicitly declared, but they must maintain consistency with the key types of other rows.\n# When data is added in the form of a list or tuple, the first element (at index 0) represents the key for that particular row, while the second element (at index 1) contains the corresponding features.\nds.append((1, {"a":1, "b":1}))\n\nds.commit()\n')),(0,i.kt)("h4",{id:"__setitem__-method"},"_","_","setitem","_","_"," Method"),(0,i.kt)("p",null,"The Dataset's ",(0,i.kt)("inlineCode",{parentName:"p"},"__setitem__")," method provides a dict-like way to add data by index."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'ds[2] = {"a":2, "b":2}\nds.commit()\n')),(0,i.kt)("h2",{id:"building-from-python-handler"},"Building from Python Handler"),(0,i.kt)("p",null,"Supports reading functions in Python files through the ",(0,i.kt)("inlineCode",{parentName:"p"},"swcli")," command line as input to build datasets. The return value of the function needs to be iterable."),(0,i.kt)("p",null,"Example python script dataset.py:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'def iter_item():\n    for i in range(100):\n        # only return features. key is auto increment index.\n        yield {"a": i, "b": i}\n\ndef iter_item_with_key():\n    for i in range(100):\n        # key + features\n        yield i, {"a": i, "b": i}\n')),(0,i.kt)("p",null,"Build datasets by triggering through the ",(0,i.kt)("inlineCode",{parentName:"p"},"swcli")," command line:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"swcli dataset build --handler dataset:iter_item --name test1\nswcli dataset build --handler dataset:iter_item_with_key --name test2\n")))}c.isMDXComponent=!0}}]);
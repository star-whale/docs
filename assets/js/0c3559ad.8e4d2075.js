"use strict";(self.webpackChunkstarwhale_docs=self.webpackChunkstarwhale_docs||[]).push([[12685],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>c});var n=a(67294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var p=n.createContext({}),s=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},u=function(e){var t=s(e.components);return n.createElement(p.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,i=e.originalType,p=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),m=s(a),c=l,k=m["".concat(p,".").concat(c)]||m[c]||d[c]||i;return a?n.createElement(k,r(r({ref:t},u),{},{components:a})):n.createElement(k,r({ref:t},u))}));function c(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var i=a.length,r=new Array(i);r[0]=m;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o.mdxType="string"==typeof e?e:l,r[1]=o;for(var s=2;s<i;s++)r[s]=a[s];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}m.displayName="MDXCreateElement"},60709:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>r,default:()=>d,frontMatter:()=>i,metadata:()=>o,toc:()=>s});var n=a(83117),l=(a(67294),a(3905));const i={title:"Starwhale Model Evaluation SDK"},r=void 0,o={unversionedId:"reference/sdk/evaluation",id:"version-0.5.10/reference/sdk/evaluation",title:"Starwhale Model Evaluation SDK",description:"@evaluation.predict",source:"@site/versioned_docs/version-0.5.10/reference/sdk/evaluation.md",sourceDirName:"reference/sdk",slug:"/reference/sdk/evaluation",permalink:"/0.5.10/reference/sdk/evaluation",draft:!1,editUrl:"https://github.com/star-whale/docs/tree/main/versioned_docs/version-0.5.10/reference/sdk/evaluation.md",tags:[],version:"0.5.10",frontMatter:{title:"Starwhale Model Evaluation SDK"},sidebar:"mainSidebar",previous:{title:"Starwhale Data Types",permalink:"/0.5.10/reference/sdk/type"},next:{title:"Starwhale Model SDK",permalink:"/0.5.10/reference/sdk/model"}},p={},s=[{value:"@evaluation.predict",id:"evaluationpredict",level:2},{value:"Parameters",id:"predict-params",level:3},{value:"Input",id:"predict-input",level:3},{value:"Examples",id:"predict-example",level:3},{value:"@evaluation.evaluate",id:"evaluationevaluate",level:2},{value:"Parameters",id:"evaluate-params",level:3},{value:"Input",id:"evaluate-input",level:3},{value:"Examples",id:"evaluate-example",level:3},{value:"evaluation.log",id:"evaluationlog",level:2},{value:"Parameters",id:"log-params",level:3},{value:"Examples",id:"log-example",level:3},{value:"evaluation.log_summary",id:"evaluationlog_summary",level:2},{value:"Examples",id:"log-s-example",level:3},{value:"evaluation.iter",id:"evaluationiter",level:2},{value:"Parameters",id:"iter-params",level:3},{value:"Examples",id:"iter-example",level:3},{value:"@handler",id:"handler",level:2},{value:"Parameters",id:"handler-params",level:3},{value:"Examples",id:"handler-example",level:3},{value:"@fine_tune",id:"fine_tune",level:2},{value:"Parameters",id:"ft-params",level:3},{value:"Examples",id:"ft-example",level:3},{value:"@multi_classification",id:"multi_classification",level:2},{value:"Parameters",id:"mc-params",level:3},{value:"Examples",id:"mc-example",level:3},{value:"PipelineHandler",id:"pipelinehandler",level:2},{value:"Parameters",id:"pl-params",level:3},{value:"Examples",id:"pl-example",level:3},{value:"Context",id:"context",level:2},{value:"Examples",id:"context-example",level:3},{value:"@starwhale.api.service.api",id:"starwhaleapiserviceapi",level:2},{value:"Examples",id:"api-example",level:3},{value:"starwhale.api.service.Service",id:"starwhaleapiserviceservice",level:2},{value:"Custom Request and Response",id:"custom-request-and-response",level:3}],u={toc:s};function d(e){let{components:t,...a}=e;return(0,l.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h2",{id:"evaluationpredict"},"@evaluation.predict"),(0,l.kt)("p",null,"The ",(0,l.kt)("inlineCode",{parentName:"p"},"@evaluation.predict")," decorator defines the inference process in the Starwhale Model Evaluation, similar to the ",(0,l.kt)("inlineCode",{parentName:"p"},"map")," phase in MapReduce. It contains the following core features:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"On the Server instance, require the resources needed to run."),(0,l.kt)("li",{parentName:"ul"},"Automatically read the local or remote datasets, and pass the data in the datasets one by one or in batches to the function decorated by ",(0,l.kt)("inlineCode",{parentName:"li"},"evaluation.predict"),"."),(0,l.kt)("li",{parentName:"ul"},"By the replicas setting, implement ",(0,l.kt)("strong",{parentName:"li"},"distributed dataset consumption")," to horizontally scale and shorten the time required for the model evaluation tasks."),(0,l.kt)("li",{parentName:"ul"},"Automatically store the return values of the function and the input features of the dataset into the ",(0,l.kt)("inlineCode",{parentName:"li"},"results")," table, for display in the Web UI and further use in the ",(0,l.kt)("inlineCode",{parentName:"li"},"evaluate")," phase."),(0,l.kt)("li",{parentName:"ul"},"The decorated function is called once for each single piece of data or each batch, to complete the inference process.")),(0,l.kt)("h3",{id:"predict-params"},"Parameters"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"resources"),": (dict, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Defines the resources required by each ",(0,l.kt)("inlineCode",{parentName:"li"},"predict")," task when running on the Server instance, including ",(0,l.kt)("inlineCode",{parentName:"li"},"mem"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"cpu"),", and ",(0,l.kt)("inlineCode",{parentName:"li"},"nvidia.com/gpu"),"."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"mem"),": The unit is Bytes, int and float types are supported.",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Supports setting ",(0,l.kt)("inlineCode",{parentName:"li"},"request")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"limit")," as a dictionary, e.g. ",(0,l.kt)("inlineCode",{parentName:"li"},'resources={"mem": {"request": 100 * 1024, "limit": 200 * 1024}}'),"."),(0,l.kt)("li",{parentName:"ul"},"If only a single number is set, the Python SDK will automatically set ",(0,l.kt)("inlineCode",{parentName:"li"},"request")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"limit")," to the same value, e.g. ",(0,l.kt)("inlineCode",{parentName:"li"},'resources={"mem": 100 * 1024}')," is ",(0,l.kt)("em",{parentName:"li"},"equivalent")," to ",(0,l.kt)("inlineCode",{parentName:"li"},'resources={"mem": {"request": 100 * 1024, "limit": 100 * 1024}}'),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"cpu"),": The unit is the number of CPU cores, int and float types are supported.",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Supports setting ",(0,l.kt)("inlineCode",{parentName:"li"},"request")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"limit")," as a dictionary, e.g. ",(0,l.kt)("inlineCode",{parentName:"li"},'resources={"cpu": {"request": 1, "limit": 2}}'),"."),(0,l.kt)("li",{parentName:"ul"},"If only a single number is set, the SDK will automatically set ",(0,l.kt)("inlineCode",{parentName:"li"},"request")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"limit")," to the same value, e.g. ",(0,l.kt)("inlineCode",{parentName:"li"},'resources={"cpu": 1.5}')," is equivalent to ",(0,l.kt)("inlineCode",{parentName:"li"},'resources={"cpu": {"request": 1.5, "limit": 1.5}}'),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"nvidia.com/gpu"),": The unit is the number of GPUs, int type is supported.",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"nvidia.com/gpu")," does not support setting ",(0,l.kt)("inlineCode",{parentName:"li"},"request")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"limit"),", only a single number is supported."))),(0,l.kt)("li",{parentName:"ul"},"Note: ",(0,l.kt)("strong",{parentName:"li"},"The ",(0,l.kt)("inlineCode",{parentName:"strong"},"resources")," parameter currently only takes effect on the Server instances"),". For the Cloud instances, the same can be achieved by selecting the corresponding ",(0,l.kt)("strong",{parentName:"li"},"resource pool")," when submitting the evaluation task. Standalone instances do not support this feature at all."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"replicas"),": (int, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"The number of replicas to run ",(0,l.kt)("inlineCode",{parentName:"li"},"predict"),"."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"predict")," defines a ",(0,l.kt)("inlineCode",{parentName:"li"},"Step"),", in which there are multiple equivalent ",(0,l.kt)("inlineCode",{parentName:"li"},"Tasks"),". Each ",(0,l.kt)("inlineCode",{parentName:"li"},"Task")," runs on a Pod in Cloud/Server instances, and a Thread in Standalone instances."),(0,l.kt)("li",{parentName:"ul"},"When multiple replicas are specified, they are equivalent and will jointly consume the selected dataset to achieve ",(0,l.kt)("strong",{parentName:"li"},"distributed dataset consumption"),". It can be understood that a row in the dataset will only be read by one ",(0,l.kt)("inlineCode",{parentName:"li"},"predict")," replica."),(0,l.kt)("li",{parentName:"ul"},"The default is 1."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"batch_size"),": (int, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Batch size for passing data from the dataset into the function."),(0,l.kt)("li",{parentName:"ul"},"The default is 1."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"fail_on_error"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},'Whether to interrupt the entire model evaluation when the decorated function throws an exception. If you expect some "exceptional" data to cause evaluation failures but don\'t want to interrupt the overall evaluation, you can set ',(0,l.kt)("inlineCode",{parentName:"li"},"fail_on_error=False"),"."),(0,l.kt)("li",{parentName:"ul"},"The default is ",(0,l.kt)("inlineCode",{parentName:"li"},"True"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"auto_log"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Whether to automatically log the return values of the function and the input features of the dataset to the ",(0,l.kt)("inlineCode",{parentName:"li"},"results")," table."),(0,l.kt)("li",{parentName:"ul"},"The default is ",(0,l.kt)("inlineCode",{parentName:"li"},"True"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"log_mode"),": (str, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"When ",(0,l.kt)("inlineCode",{parentName:"li"},"auto_log=True"),", you can set ",(0,l.kt)("inlineCode",{parentName:"li"},"log_mode")," to define logging the return values in ",(0,l.kt)("inlineCode",{parentName:"li"},"plain")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"pickle")," format."),(0,l.kt)("li",{parentName:"ul"},"The default is ",(0,l.kt)("inlineCode",{parentName:"li"},"pickle"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"log_dataset_features"),": (List","[str]",", optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"When ",(0,l.kt)("inlineCode",{parentName:"li"},"auto_log=True"),", you can selectively log certain features from the dataset via this parameter."),(0,l.kt)("li",{parentName:"ul"},"By default, all features will be logged."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"needs"),": (List","[Callable]",", optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Defines the prerequisites for this task to run, can use the needs syntax to implement DAG."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"needs")," accepts functions decorated by ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.evaluate"),", and ",(0,l.kt)("inlineCode",{parentName:"li"},"@handler"),"."),(0,l.kt)("li",{parentName:"ul"},"The default is empty, i.e. does not depend on any other tasks.")))),(0,l.kt)("h3",{id:"predict-input"},"Input"),(0,l.kt)("p",null,"The decorated functions need to define some input parameters to accept dataset data, etc. They contain the following patterns:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"p"},"data"),":"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"data")," is a dict type that can read the features of the dataset."),(0,l.kt)("li",{parentName:"ul"},"When ",(0,l.kt)("inlineCode",{parentName:"li"},"batch_size=1")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"batch_size")," is not set, the label feature can be read through ",(0,l.kt)("inlineCode",{parentName:"li"},"data['label']")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"data.label"),"."),(0,l.kt)("li",{parentName:"ul"},"When ",(0,l.kt)("inlineCode",{parentName:"li"},"batch_size")," is set to > 1, ",(0,l.kt)("inlineCode",{parentName:"li"},"data")," is a list.")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from starwhale import evaluation\n\n@evaluation.predict\ndef predict(data):\n    print(data['label'])\n    print(data.label)\n"))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"p"},"data")," + ",(0,l.kt)("inlineCode",{parentName:"p"},"external"),":"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"data")," is a dict type that can read the features of the dataset."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"external")," is also a dict, including: ",(0,l.kt)("inlineCode",{parentName:"li"},"index"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"index_with_dataset"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"dataset_info"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"context")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"dataset_uri")," keys. The attributes can be used for the further fine-grained processing.",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"index"),": The index of the dataset row."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"index_with_dataset"),": The index with the dataset info."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"dataset_info"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"starwhale.core.dataset.tabular.TabularDatasetInfo")," Class."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"context"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"starwhale.Context")," Class."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"dataset_uri"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"starwhale.nase.uri.resource.Resource")," Class.")))),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import evaluation\n\n@evaluation.predict\ndef predict(data, external):\n    print(data[\'label\'])\n    print(data.label)\n    print(external["context"])\n    print(external["dataset_uri"])\n'))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"p"},"data")," + ",(0,l.kt)("inlineCode",{parentName:"p"},"**kw"),":"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"data")," is a dict type that can read the features of the dataset."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"kw")," is a dict that contains ",(0,l.kt)("inlineCode",{parentName:"li"},"external"),".")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import evaluation\n\n@evaluation.predict\ndef predict(data, **kw):\n    print(kw["external"]["context"])\n    print(kw["external"]["dataset_uri"])\n'))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"p"},"*args")," + ",(0,l.kt)("inlineCode",{parentName:"p"},"**kwargs"),":"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"The first argument of args list is ",(0,l.kt)("inlineCode",{parentName:"li"},"data"),".")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import evaluation\n\n@evaluation.predict\ndef predict(*args, **kw):\n    print(args[0].label)\n    print(args[0]["label"])\n    print(kw["external"]["context"])\n'))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"p"},"**kwargs"),":"),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import evaluation\n\n@evaluation.predict\ndef predict(**kw):\n    print(kw["data"].label)\n    print(kw["data"]["label"])\n    print(kw["external"]["context"])\n'))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"p"},"*args"),":"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"*args")," does not contain ",(0,l.kt)("inlineCode",{parentName:"li"},"external"),".")),(0,l.kt)("pre",{parentName:"li"},(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import evaluation\n\n@evaluation.predict\ndef predict(*args):\n    print(args[0].label)\n    print(args[0]["label"])\n')))),(0,l.kt)("h3",{id:"predict-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import evaluation\n\n@evaluation.predict\ndef predict_image(data):\n    ...\n\n@evaluation.predict(\n    dataset="mnist/version/latest",\n    batch_size=32,\n    replicas=4,\n    needs=[predict_image],\n)\ndef predict_batch_images(batch_data)\n    ...\n\n@evaluation.predict(\n    resources={"nvidia.com/gpu": 1,\n               "cpu": {"request": 1, "limit": 2},\n               "mem": 200 * 1024},  # 200MB\n    log_mode="plain",\n)\ndef predict_with_resources(data):\n    ...\n\n@evaluation.predict(\n    replicas=1,\n    log_mode="plain",\n    log_dataset_features=["txt", "img", "label"],\n)\ndef predict_with_selected_features(data):\n    ...\n')),(0,l.kt)("h2",{id:"evaluationevaluate"},"@evaluation.evaluate"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"@evaluation.evaluate")," is a decorator that defines the evaluation process in the Starwhale Model evaluation, similar to the reduce phase in MapReduce. It contains the following core features:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"On the Server instance, apply for the resources."),(0,l.kt)("li",{parentName:"ul"},"Read the data recorded in the ",(0,l.kt)("inlineCode",{parentName:"li"},"results")," table automatically during the ",(0,l.kt)("inlineCode",{parentName:"li"},"predict")," phase, and pass it into the function as an iterator."),(0,l.kt)("li",{parentName:"ul"},"The ",(0,l.kt)("inlineCode",{parentName:"li"},"evaluate")," phase will only run one replica, and cannot define the ",(0,l.kt)("inlineCode",{parentName:"li"},"replicas")," parameter like the ",(0,l.kt)("inlineCode",{parentName:"li"},"predict")," phase.")),(0,l.kt)("h3",{id:"evaluate-params"},"Parameters"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"resources"),": (dict, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Consistent with the ",(0,l.kt)("inlineCode",{parentName:"li"},"resources")," parameter definition in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"needs"),": (List","[Callable]",", optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Consistent with the ",(0,l.kt)("inlineCode",{parentName:"li"},"needs")," parameter definition in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."),(0,l.kt)("li",{parentName:"ul"},"In the common case, it will depend on a function decorated by ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"use_predict_auto_log"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Defaults to ",(0,l.kt)("inlineCode",{parentName:"li"},"True"),", passes an iterator that can traverse the ",(0,l.kt)("inlineCode",{parentName:"li"},"predict")," results to the function.")))),(0,l.kt)("h3",{id:"evaluate-input"},"Input"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"When ",(0,l.kt)("inlineCode",{parentName:"li"},"use_predict_auto_log=True")," (default), pass an iterator that can traverse the ",(0,l.kt)("inlineCode",{parentName:"li"},"predict")," results into the function.",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"The iterated object is a dictionary containing two keys: ",(0,l.kt)("inlineCode",{parentName:"li"},"output")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"input"),".",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"output")," is the element returned by the ",(0,l.kt)("inlineCode",{parentName:"li"},"predict")," stage function."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"input")," is the features of the corresponding dataset during the inference process, which is a dictionary type."))))),(0,l.kt)("li",{parentName:"ul"},"When ",(0,l.kt)("inlineCode",{parentName:"li"},"use_predict_auto_log=False"),", do not pass any parameters into the function.")),(0,l.kt)("h3",{id:"evaluate-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from starwhale import evaluation\n\n@evaluation.evaluate(needs=[predict_image])\ndef evaluate_results(predict_result_iter):\n    ...\n\n@evaluation.evaluate(\n    use_predict_auto_log=False,\n    needs=[predict_image],\n)\ndef evaluate_results():\n    ...\n")),(0,l.kt)("h2",{id:"evaluationlog"},"evaluation.log"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"evaluation.log")," is a function that logs the certain evaluation metrics to the specific tables, which can be viewed as the Web page in the Server/Cloud instance."),(0,l.kt)("h3",{id:"log-params"},"Parameters"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"category"),": (str, required)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"The category of the logged record, which will be used as a suffix for the Starwhale Datastore table name."),(0,l.kt)("li",{parentName:"ul"},"Each ",(0,l.kt)("inlineCode",{parentName:"li"},"category")," corresponds to a Starwhale Datastore table, with these tables isolated by evaluation task ID without affecting each other."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"id"),": (str|int, required)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"The ID of the logged record, unique within the table."),(0,l.kt)("li",{parentName:"ul"},"Only one type, either str or int, can be used as ID type in the same table."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"metrics"),": (dict, required)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"A dictionary recording metrics in key-value pairs.")))),(0,l.kt)("h3",{id:"log-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import evaluation\n\nevaluation.log("label/1", 1, {"loss": 0.99, "accuracy": 0.98})\nevaluation.log("ppl", "1", {"a": "test", "b": 1})\n')),(0,l.kt)("h2",{id:"evaluationlog_summary"},"evaluation.log_summary"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"evaluation.log_summary")," is a function that logs the certain metrics to the summary table. The evaluation page of a Server/Cloud instance displays data from the summary table."),(0,l.kt)("p",null,"Each time it is called, Starwhale automatically updates the table using the unique ID of the current evaluation as the row ID. This function can be called multiple times during an evaluation to update different columns."),(0,l.kt)("p",null,"Each project has one summary table, and all evaluation jobs under that project will log their summary information into this table."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"@classmethod\ndef log_summary(cls, *args: t.Any, **kw: t.Any) -> None:\n")),(0,l.kt)("h3",{id:"log-s-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import evaluation\n\nevaluation.log_summary(loss=0.99)\nevaluation.log_summary(loss=0.99, accuracy=0.99)\nevaluation.log_summary({"loss": 0.99, "accuracy": 0.99})\n')),(0,l.kt)("h2",{id:"evaluationiter"},"evaluation.iter"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"evaluation.iter")," is a function that returns an iterator for reading data iteratively from certain model evaluation tables."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"@classmethod\ndef iter(cls, category: str) -> t.Iterator:\n")),(0,l.kt)("h3",{id:"iter-params"},"Parameters"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"category"),": (str, required)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"This parameter is consistent with the meaning of the ",(0,l.kt)("inlineCode",{parentName:"li"},"category")," parameter in the ",(0,l.kt)("inlineCode",{parentName:"li"},"evaluation.log")," function.")))),(0,l.kt)("h3",{id:"iter-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import evaluation\n\nresults = [data for data in evaluation.iter("label/0")]\n')),(0,l.kt)("h2",{id:"handler"},"@handler"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"@handler")," is a decorator that provides the following functionalities:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"On a Server instance, it requests the required resources to run."),(0,l.kt)("li",{parentName:"ul"},"It can control the number of replicas."),(0,l.kt)("li",{parentName:"ul"},"Multiple handlers can form a DAG through dependency relationships to control the execution workflow."),(0,l.kt)("li",{parentName:"ul"},"It can expose ports externally to run like a web handler.")),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"@fine_tune"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"@evaluation.predict")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"@evaluation.evalute")," can be considered applications of ",(0,l.kt)("inlineCode",{parentName:"p"},"@handler")," in the certain specific areas. ",(0,l.kt)("inlineCode",{parentName:"p"},"@handler")," is the underlying implementation of these decorators and is more fundamental and flexible."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'@classmethod\ndef handler(\n    cls,\n    resources: t.Optional[t.Dict[str, t.Any]] = None,\n    replicas: int = 1,\n    needs: t.Optional[t.List[t.Callable]] = None,\n    name: str = "",\n    expose: int = 0,\n    require_dataset: bool = False,\n) -> t.Callable:\n')),(0,l.kt)("h3",{id:"handler-params"},"Parameters"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"resources"),": (dict, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Consistent with the ",(0,l.kt)("inlineCode",{parentName:"li"},"resources")," parameter definition in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"needs"),": (List","[Callable]",", optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Consistent with the ",(0,l.kt)("inlineCode",{parentName:"li"},"needs")," parameter definition in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"replicas"),": (int, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Consistent with the ",(0,l.kt)("inlineCode",{parentName:"li"},"replicas")," parameter definition in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"name"),": (str, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"The name displayed for the handler."),(0,l.kt)("li",{parentName:"ul"},"If not specified, use the decorated function's name."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"expose"),": (int, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"The port exposed externally. When running a web handler, the exposed port needs to be declared."),(0,l.kt)("li",{parentName:"ul"},"The default is 0, meaning no port is exposed."),(0,l.kt)("li",{parentName:"ul"},"Currently only one port can be exposed."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"require_dataset"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Defines whether this handler requires a dataset when running."),(0,l.kt)("li",{parentName:"ul"},"If ",(0,l.kt)("inlineCode",{parentName:"li"},"required_dataset=True"),", the user is required to input a dataset when creating an evaluation task on the Server/Cloud instance web page. If ",(0,l.kt)("inlineCode",{parentName:"li"},"required_dataset=False"),", the user does not need to specify a dataset on the web page."),(0,l.kt)("li",{parentName:"ul"},"The default is ",(0,l.kt)("inlineCode",{parentName:"li"},"False"),".")))),(0,l.kt)("h3",{id:"handler-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import handler\nimport gradio\n\n@handler(resources={"cpu": 1, "nvidia.com/gpu": 1}, replicas=3)\ndef my_handler():\n    ...\n\n@handler(needs=[my_handler])\ndef my_another_handler():\n    ...\n\n@handler(expose=7860)\ndef chatbot():\n    with gradio.Blocks() as server:\n        ...\n    server.launch(server_name="0.0.0.0", server_port=7860)\n')),(0,l.kt)("h2",{id:"fine_tune"},"@fine_tune"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"fine_tune")," is a decorator that defines the fine-tuning process for model training."),(0,l.kt)("p",null,"Some restrictions and usage suggestions:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"fine_tune")," has only one replica."),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"fine_tune")," requires dataset input."),(0,l.kt)("li",{parentName:"ul"},"Generally, the dataset is obtained through ",(0,l.kt)("inlineCode",{parentName:"li"},"Context.get_runtime_context()")," at the start of ",(0,l.kt)("inlineCode",{parentName:"li"},"fine_tune"),"."),(0,l.kt)("li",{parentName:"ul"},"Generally, at the end of ",(0,l.kt)("inlineCode",{parentName:"li"},"fine_tune"),", the fine-tuned Starwhale model package is generated through ",(0,l.kt)("inlineCode",{parentName:"li"},"starwhale.model.build"),", which will be automatically copied to the corresponding evaluation project.")),(0,l.kt)("h3",{id:"ft-params"},"Parameters"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"resources"),": (dict, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Consistent with the ",(0,l.kt)("inlineCode",{parentName:"li"},"resources")," parameter definition in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"needs"),": (List","[Callable]",", optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Consistent with the ",(0,l.kt)("inlineCode",{parentName:"li"},"needs")," parameter definition in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),".")))),(0,l.kt)("h3",{id:"ft-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import model as starwhale_model\nfrom starwhale import fine_tune, Context\n\n@fine_tune(resources={"nvidia.com/gpu": 1})\ndef llama_fine_tuning():\n    ctx = Context.get_runtime_context()\n\n    if len(ctx.dataset_uris) == 2:\n        # TODO: use more graceful way to get train and eval dataset\n        train_dataset = dataset(ctx.dataset_uris[0], readonly=True, create="forbid")\n        eval_dataset = dataset(ctx.dataset_uris[1], readonly=True, create="forbid")\n    elif len(ctx.dataset_uris) == 1:\n        train_dataset = dataset(ctx.dataset_uris[0], readonly=True, create="forbid")\n        eval_dataset = None\n    else:\n        raise ValueError("Only support 1 or 2 datasets(train and eval dataset) for now")\n\n    #user training code\n    train_llama(\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n    )\n\n    model_name = get_model_name()\n    starwhale_model.build(name=f"llama-{model_name}-qlora-ft")\n')),(0,l.kt)("h2",{id:"multi_classification"},"@multi_classification"),(0,l.kt)("p",null,"The ",(0,l.kt)("inlineCode",{parentName:"p"},"@multi_classification")," decorator uses the sklearn lib to analyze results for multi-classification problems, outputting the confusion matrix, ROC, AUC etc., and writing them to related tables in the Starwhale Datastore."),(0,l.kt)("p",null,"When using it, certain requirements are placed on the return value of the decorated function, which should be ",(0,l.kt)("inlineCode",{parentName:"p"},"(label, result)")," or ",(0,l.kt)("inlineCode",{parentName:"p"},"(label, result, probability_matrix)"),"."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'def multi_classification(\n    confusion_matrix_normalize: str = "all",\n    show_hamming_loss: bool = True,\n    show_cohen_kappa_score: bool = True,\n    show_roc_auc: bool = True,\n    all_labels: t.Optional[t.List[t.Any]] = None,\n) -> t.Any:\n')),(0,l.kt)("h3",{id:"mc-params"},"Parameters"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"confusion_matrix_normalize"),": (str, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Accepts three parameters:",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"true"),": rows"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"pred"),": columns"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"all"),": rows+columns"))))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"show_hamming_loss"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Whether to calculate the Hamming loss."),(0,l.kt)("li",{parentName:"ul"},"The default is ",(0,l.kt)("inlineCode",{parentName:"li"},"True"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"show_cohen_kappa_score"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Whether to calculate the Cohen kappa score."),(0,l.kt)("li",{parentName:"ul"},"The default is ",(0,l.kt)("inlineCode",{parentName:"li"},"True"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"show_roc_auc"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Whether to calculate ROC/AUC. To calculate, the function needs to return a (label, result, probability_matrix) tuple, otherwise a (label, result) tuple is sufficient."),(0,l.kt)("li",{parentName:"ul"},"The default is ",(0,l.kt)("inlineCode",{parentName:"li"},"True"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"all_labels"),": (List, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Defines all the labels.")))),(0,l.kt)("h3",{id:"mc-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'\n@multi_classification(\n    confusion_matrix_normalize="all",\n    show_hamming_loss=True,\n    show_cohen_kappa_score=True,\n    show_roc_auc=True,\n    all_labels=[i for i in range(0, 10)],\n)\ndef evaluate(ppl_result) -> t.Tuple[t.List[int], t.List[int], t.List[t.List[float]]]:\n    label, result, probability_matrix = [], [], []\n    return label, result, probability_matrix\n\n@multi_classification(\n    confusion_matrix_normalize="all",\n    show_hamming_loss=True,\n    show_cohen_kappa_score=True,\n    show_roc_auc=False,\n    all_labels=[i for i in range(0, 10)],\n)\ndef evaluate(ppl_result) -> t.Tuple[t.List[int], t.List[int], t.List[t.List[float]]]:\n    label, result = [], [], []\n    return label, result\n')),(0,l.kt)("h2",{id:"pipelinehandler"},"PipelineHandler"),(0,l.kt)("p",null,"The ",(0,l.kt)("inlineCode",{parentName:"p"},"PipelineHandler")," class provides a default model evaluation workflow definition that requires users to implement the predict and evaluate functions."),(0,l.kt)("p",null,"The ",(0,l.kt)("inlineCode",{parentName:"p"},"PipelineHandler")," is equivalent to using the ",(0,l.kt)("inlineCode",{parentName:"p"},"@evaluation.predict")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"@evaluation.evaluate")," decorators together - the usage looks different but the underlying model evaluation process is the same."),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Note that PipelineHandler currently does not support defining resources parameters.")),(0,l.kt)("p",null,"Users need to implement the following functions:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"p"},"predict"),": Defines the inference process, equivalent to a function decorated with ",(0,l.kt)("inlineCode",{parentName:"p"},"@evaluation.predict"),".")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"p"},"evaluate"),": Defines the evaluation process, equivalent to a function decorated with ",(0,l.kt)("inlineCode",{parentName:"p"},"@evaluation.evaluate"),"."))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"from typing import Any, Iterator\nfrom abc import ABCMeta, abstractmethod\n\nclass PipelineHandler(metaclass=ABCMeta):\n    def __init__(\n        self,\n        predict_batch_size: int = 1,\n        ignore_error: bool = False,\n        predict_auto_log: bool = True,\n        predict_log_mode: str = PredictLogMode.PICKLE.value,\n        predict_log_dataset_features: t.Optional[t.List[str]] = None,\n        **kwargs: t.Any,\n    ) -> None:\n        self.context = Context.get_runtime_context()\n        ...\n\n    def predict(self, data: Any, **kw: Any) -> Any:\n        raise NotImplementedError\n\n    def evaluate(self, ppl_result: Iterator) -> Any\n        raise NotImplementedError\n")),(0,l.kt)("h3",{id:"pl-params"},"Parameters"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"predict_batch_size"),": (int, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Equivalent to the ",(0,l.kt)("inlineCode",{parentName:"li"},"batch_size")," parameter in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."),(0,l.kt)("li",{parentName:"ul"},"Default is 1."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"ignore_error"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Equivalent to the ",(0,l.kt)("inlineCode",{parentName:"li"},"fail_on_error")," parameter in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."),(0,l.kt)("li",{parentName:"ul"},"Default is ",(0,l.kt)("inlineCode",{parentName:"li"},"False"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"predict_auto_log"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Equivalent to the ",(0,l.kt)("inlineCode",{parentName:"li"},"auto_log")," parameter in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."),(0,l.kt)("li",{parentName:"ul"},"Default is ",(0,l.kt)("inlineCode",{parentName:"li"},"True"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"predict_log_mode"),": (str, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Equivalent to the ",(0,l.kt)("inlineCode",{parentName:"li"},"log_mode")," parameter in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."),(0,l.kt)("li",{parentName:"ul"},"Default is ",(0,l.kt)("inlineCode",{parentName:"li"},"pickle"),"."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"predict_log_dataset_features"),": (bool, optional)",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Equivalent to the ",(0,l.kt)("inlineCode",{parentName:"li"},"log_dataset_features parameter")," in ",(0,l.kt)("inlineCode",{parentName:"li"},"@evaluation.predict"),"."),(0,l.kt)("li",{parentName:"ul"},"Default is ",(0,l.kt)("inlineCode",{parentName:"li"},"None"),", which records all features.")))),(0,l.kt)("h3",{id:"pl-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'import typing as t\n\nimport torch\nfrom starwhale import PipelineHandler\n\nclass Example(PipelineHandler):\n    def __init__(self) -> None:\n        super().__init__()\n        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")\n        self.model = self._load_model(self.device)\n\n    def predict(self, data: t.Dict):\n        data_tensor = self._pre(data.img)\n        output = self.model(data_tensor)\n        return self._post(output)\n\n    def evaluate(self, ppl_result):\n        result, label, pr = [], [], []\n        for _data in ppl_result:\n            label.append(_data["input"]["label"])\n            result.extend(_data["output"][0])\n            pr.extend(_data["output"][1])\n        return label, result, pr\n\n    def _pre(self, input: Image) -> torch.Tensor:\n        ...\n\n    def _post(self, input):\n        ...\n\n    def _load_model(self, device):\n        ...\n')),(0,l.kt)("h2",{id:"context"},"Context"),(0,l.kt)("p",null,"The context information passed during model evaluation, including Project, Task ID, etc. The Context content is automatically injected and can be used in the following ways:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Inherit the ",(0,l.kt)("inlineCode",{parentName:"li"},"PipelineHandler")," class and use the ",(0,l.kt)("inlineCode",{parentName:"li"},"self.context")," object."),(0,l.kt)("li",{parentName:"ul"},"Get it through ",(0,l.kt)("inlineCode",{parentName:"li"},"Context.get_runtime_context()"),".")),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Note that ",(0,l.kt)("inlineCode",{parentName:"strong"},"Context")," can only be used during model evaluation, otherwise the program will throw an exception.")),(0,l.kt)("p",null,"Currently Context can get the following values:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"project"),": str",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Project name."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"version"),": str",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Unique ID of model evaluation."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"step"),": str",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Step name."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"total"),": int",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Total number of Tasks under the Step."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"index"),": int",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Task index number, starting from 0."))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"dataset_uris"),": List","[str]",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"List of Starwhale dataset URIs.")))),(0,l.kt)("h3",{id:"context-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"\nfrom starwhale import Context, PipelineHandler\n\ndef func():\n    ctx = Context.get_runtime_context()\n    print(ctx.project)\n    print(ctx.version)\n    print(ctx.step)\n    ...\n\nclass Example(PipelineHandler):\n\n    def predict(self, data: t.Dict):\n        print(self.context.project)\n        print(self.context.version)\n        print(self.context.step)\n")),(0,l.kt)("h2",{id:"starwhaleapiserviceapi"},"@starwhale.api.service.api"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},"@starwhale.api.service.api")," is a decorator that provides a simple Web Handler input definition based on Gradio for accepting external requests and returning inference results to the user when launching a Web Service with the ",(0,l.kt)("inlineCode",{parentName:"p"},"swcli model serve")," command, enabling online evaluation."),(0,l.kt)("h3",{id:"api-example"},"Examples"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'import gradio\nfrom starwhale.api.service import api\n\ndef predict_image(img):\n    ...\n\n@api(gradio.File(), gradio.Label())\ndef predict_view(file: t.Any) -> t.Any:\n    with open(file.name, "rb") as f:\n        data = Image(f.read(), shape=(28, 28, 1))\n    _, prob = predict_image({"img": data})\n    return {i: p for i, p in enumerate(prob)}\n')),(0,l.kt)("h2",{id:"starwhaleapiserviceservice"},"starwhale.api.service.Service"),(0,l.kt)("p",null,"If you want to customize the web service implementation, you can subclass ",(0,l.kt)("inlineCode",{parentName:"p"},"Service")," and override the ",(0,l.kt)("inlineCode",{parentName:"p"},"serve")," method."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"class CustomService(Service):\n    def serve(self, addr: str, port: int, handler_list: t.List[str] = None) -> None:\n        ...\n\nsvc = CustomService()\n\n@svc.api(...)\ndef handler(data):\n    ...\n")),(0,l.kt)("p",null,"Notes:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Handlers added with ",(0,l.kt)("inlineCode",{parentName:"li"},"PipelineHandler.add_api")," and the ",(0,l.kt)("inlineCode",{parentName:"li"},"api")," decorator or ",(0,l.kt)("inlineCode",{parentName:"li"},"Service.api")," can work together"),(0,l.kt)("li",{parentName:"ul"},"If using a custom ",(0,l.kt)("inlineCode",{parentName:"li"},"Service"),", you need to instantiate the custom Service class in the model")),(0,l.kt)("h3",{id:"custom-request-and-response"},"Custom Request and Response"),(0,l.kt)("p",null,"Request and Response are handler preprocessing and postprocessing classes for receiving user requests and returning results. They can be simply understood as pre and post logic for the ",(0,l.kt)("inlineCode",{parentName:"p"},"handler"),"."),(0,l.kt)("p",null,"Starwhale provides built-in Request implementations for Dataset types and Json Response. Users can also customize the logic as follows:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'import typing as t\n\nfrom starwhale.api.service import (\n    Request,\n    Service,\n    Response,\n)\n\nclass CustomInput(Request):\n    def load(self, req: t.Any) -> t.Any:\n        return req\n\nclass CustomOutput(Response):\n    def __init__(self, prefix: str) -> None:\n        self.prefix = prefix\n\n    def dump(self, req: str) -> bytes:\n        return f"{self.prefix} {req}".encode("utf-8")\n\nsvc = Service()\n\n@svc.api(request=CustomInput(), response=CustomOutput("hello"))\ndef foo(data: t.Any) -> t.Any:\n    ...\n')))}d.isMDXComponent=!0}}]);
"use strict";(self.webpackChunkstarwhale_docs=self.webpackChunkstarwhale_docs||[]).push([[80686],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>u});var a=n(67294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),d=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},c=function(e){var t=d(e.components);return a.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),p=d(n),u=i,g=p["".concat(l,".").concat(u)]||p[u]||m[u]||r;return n?a.createElement(g,s(s({ref:t},c),{},{components:n})):a.createElement(g,s({ref:t},c))}));function u(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,s=new Array(r);s[0]=p;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o.mdxType="string"==typeof e?e:i,s[1]=o;for(var d=2;d<r;d++)s[d]=n[d];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},86162:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>r,metadata:()=>o,toc:()=>d});var a=n(83117),i=(n(67294),n(3905));const r={title:"Dataset Versioning"},s=void 0,o={unversionedId:"dataset/version",id:"version-0.6.10/dataset/version",title:"Dataset Versioning",description:"Starwhale dataset supports fine-grained version control to trace changes to each row and column. The version control of Starwhale Dataset has the following features:",source:"@site/versioned_docs/version-0.6.10/dataset/version.md",sourceDirName:"dataset",slug:"/dataset/version",permalink:"/dataset/version",draft:!1,editUrl:"https://github.com/star-whale/docs/tree/main/versioned_docs/version-0.6.10/dataset/version.md",tags:[],version:"0.6.10",frontMatter:{title:"Dataset Versioning"},sidebar:"mainSidebar",previous:{title:"Dataset Visualization",permalink:"/dataset/view"},next:{title:"Integration with Other ML Libraries",permalink:"/dataset/integration"}},l={},d=[{value:"Generating Versions During Dataset Construction",id:"generating-versions-during-dataset-construction",level:2},{value:"SDK commit to Actively Create Versions",id:"sdk-commit-to-actively-create-versions",level:3},{value:"swcli Command Line",id:"swcli-command-line",level:3},{value:"Tagging Versions",id:"tagging-versions",level:3},{value:"Loading Datasets by Version",id:"loading-datasets-by-version",level:2}],c={toc:d};function m(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"Starwhale dataset supports fine-grained version control to trace changes to each row and column. The version control of Starwhale Dataset has the following features:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Linear versioning"),". The design aims at simplifying operations without complex branch and merge operations. Branch merge on massive datasets is almost impossible."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Fine-grained control"),". The minimum unit is a change to a column in a row that can generate a new version."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Unique version IDs"),". When generating a version, a globally unique ID is produced. Copying datasets between instances will keep this ID unchanged. The dataset content can be loaded by this ID.")),(0,i.kt)("h2",{id:"generating-versions-during-dataset-construction"},"Generating Versions During Dataset Construction"),(0,i.kt)("h3",{id:"sdk-commit-to-actively-create-versions"},"SDK commit to Actively Create Versions"),(0,i.kt)("p",null,"When constructing a dataset using the Starwhale Dataset SDK, after adding data, calling the ",(0,i.kt)("inlineCode",{parentName:"p"},"commit")," method will produce a new version and obtain a UUID."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import dataset\n\nds1 = dataset("new-ds", create="empty")\nds1["train/0"] = {"a": 1, "b": 10}\nds1["train/1"] = {"a": 2, "b": 20}\nversion = ds1.commit()\nprint(version)\nds1.close()\n\nds2 = dataset(f"new-ds/version/{version}")\nds2["train/0"].features.c = 100\nds2["train/1"].features.a = -2\nds2["train/1"].features.b = -20\nnew_version = ds2.commit()\nprint(new_version)\nds2.close()\n\nds1 = dataset(f"new-ds/version/{version}", readonly=True)\nprint(f"---{version}")\nprint(ds1["train/0"].index, ds1["train/0"].features)\nprint(ds1["train/1"].index, ds1["train/1"].features)\nds2 = dataset(f"new-ds/version/{new_version}", readonly=True)\nprint(f"---{new_version}")\nprint(ds2["train/0"].index, ds2["train/0"].features)\nprint(ds2["train/1"].index, ds2["train/1"].features)\nds1.close()\nds2.close()\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"n7uglydp4pbjrf5rjgct7ygmmwk6ldmzv5j3amaw\na4gyk3w3uxgklfthle2jjmxw3gx3k7m6icbzfhlf\n---n7uglydp4pbjrf5rjgct7ygmmwk6ldmzv5j3amaw\ntrain/0 {'a': 1, 'b': 10}\ntrain/1 {'a': 2, 'b': 20}\n---a4gyk3w3uxgklfthle2jjmxw3gx3k7m6icbzfhlf\ntrain/0 {'a': 1, 'b': 10, 'c': 100}\ntrain/1 {'a': -2, 'b': -20}\n")),(0,i.kt)("h3",{id:"swcli-command-line"},"swcli Command Line"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"swcli dataset build")," commands automatically generate a new version:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"\u276f swcli dataset build --json https://modelscope.cn/api/v1/datasets/damo/100PoisonMpts/repo\\?Revision\\=master\\&FilePath\\=train.jsonl\n\ud83d\udea7 start to build dataset bundle...\n\ud83d\udc77 uri local/project/self/dataset/json-gec8u5sv/version/latest\n\ud83c\udf0a creating dataset local/project/self/dataset/json-gec8u5sv/version/f3iz4sdljjt7rmmfd4rkiak4vkbilp5pbrdgfgom...\n\ud83e\udd8b update 906 records into dataset\n\ud83c\udf3a congratulation! dataset build from ('https://modelscope.cn/api/v1/datasets/damo/100PoisonMpts/repo?Revision=master&FilePath=train.jsonl',) has been built. You can run  swcli dataset info json-gec8u5sv/version/f3iz4sdljjt7\n")),(0,i.kt)("h3",{id:"tagging-versions"},"Tagging Versions"),(0,i.kt)("p",null,"Starwhale introduces the concept of Tags, which can be specified during ",(0,i.kt)("inlineCode",{parentName:"p"},"commit")," or when executing dataset construction commands to associate dataset versions with Tags, allowing dataset loading by Tag."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Dataset version: A unique ID, similar to ",(0,i.kt)("inlineCode",{parentName:"li"},"f3iz4sdljjt7rmmfd4rkiak4vkbilp5pbrdgfgom"),", ensuring the ID is unique across all Starwhale instances."),(0,i.kt)("li",{parentName:"ul"},"Dataset Tag: A readable string, similar to ",(0,i.kt)("inlineCode",{parentName:"li"},"t1"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"t2"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"v0.3"),". There is a one-to-many relationship between dataset versions and Tags. Each Tag can only identify one version, but each dataset version can have multiple Tags.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Manually specified Tags: The ",(0,i.kt)("inlineCode",{parentName:"li"},"tags")," parameter in the ",(0,i.kt)("inlineCode",{parentName:"li"},"commit")," function, or the ",(0,i.kt)("inlineCode",{parentName:"li"},"--tag")," parameter in the ",(0,i.kt)("inlineCode",{parentName:"li"},"swcli dataset build")," command, can be used to specify one or multiple Tags. When the dataset is copied to other instances, these Tags can be carried over by parameter settings."),(0,i.kt)("li",{parentName:"ul"},"Automatically generated incremental Tags: Within an instance, after each commit or build, an incremental Tag like ",(0,i.kt)("inlineCode",{parentName:"li"},"v0"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"v1"),", ",(0,i.kt)("inlineCode",{parentName:"li"},"v2")," is generated. When copying the dataset, these Tags are ignored on the source instance, and new incremental Tags are generated on the destination instance."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"latest")," Tag: Automatically generated, the last commit or build command will mark the ",(0,i.kt)("inlineCode",{parentName:"li"},"latest")," Tag on that version.")))),(0,i.kt)("h2",{id:"loading-datasets-by-version"},"Loading Datasets by Version"),(0,i.kt)("p",null,"Datasets can be loaded from any location using the Dataset URI, where the version field in the URI can take various forms such as unique IDs, unique ID abbreviations, custom Tags, incremental Tags, and the ",(0,i.kt)("inlineCode",{parentName:"p"},"latest")," Tag."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from starwhale import dataset\n\n# load with the latest version\nprint("latest version(default):", dataset("new-ds").loading_version)\nprint("latest version(specified):", dataset("new-ds/version/latest").loading_version)\n\n# load with the full specified version\nprint("uuid version(full):", dataset("new-ds/version/n7uglydp4pbjrf5rjgct7ygmmwk6ldmzv5j3amaw").loading_version)\nprint("uuid version(prefix):", dataset("new-ds/version/n7uglydp4p").loading_version)\n\n# load with tag\nprint("tag version(v0):", dataset("new-ds/version/v0").loading_version)\nprint("tag version(v1):", dataset("new-ds/version/v1").loading_version)\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},"latest version(default): a4gyk3w3uxgklfthle2jjmxw3gx3k7m6icbzfhlf\nlatest version(specified): a4gyk3w3uxgklfthle2jjmxw3gx3k7m6icbzfhlf\nuuid version(full): n7uglydp4pbjrf5rjgct7ygmmwk6ldmzv5j3amaw\nuuid version(prefix): n7uglydp4pbjrf5rjgct7ygmmwk6ldmzv5j3amaw\ntag version(v0): n7uglydp4pbjrf5rjgct7ygmmwk6ldmzv5j3amaw\ntag version(v1): a4gyk3w3uxgklfthle2jjmxw3gx3k7m6icbzfhlf\n")))}m.isMDXComponent=!0}}]);
<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://doc.starwhale.ai/blog</id>
    <title>Starwhale Blog</title>
    <updated>2023-09-11T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://doc.starwhale.ai/blog"/>
    <subtitle>Starwhale Blog</subtitle>
    <icon>https://doc.starwhale.ai/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Reporduce and compare evaluations using Starwhale]]></title>
        <id>https://doc.starwhale.ai/blog/reproduce-and-compare-evals</id>
        <link href="https://doc.starwhale.ai/blog/reproduce-and-compare-evals"/>
        <updated>2023-09-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Reproduce and compare evaluations]]></summary>
        <content type="html"><![CDATA[<p>If you have doubts about the findings of <a href="https://cloud.starwhale.cn/simple/report/preview/?rid=e9067622-fec2-4701-a960-eb142a54ff94" target="_blank" rel="noopener noreferrer">this report</a> or any other evaluations, how should you reproduce and compare the evaluation results?</p><p>Workflow: Login → Create a project → Run the model → Create a report</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="step1-login">STEP1: Login<a href="#step1-login" class="hash-link" aria-label="Direct link to STEP1: Login" title="Direct link to STEP1: Login">​</a></h3><p>First, you have to log in to the Starwhale platform by clicking on the <a href="https://cloud.starwhale.cn/login?lang=zh" target="_blank" rel="noopener noreferrer">login</a>. If you haven't registered yet, you can click on the <a href="https://cloud.starwhale.cn/signup" target="_blank" rel="noopener noreferrer">sign-up</a> to create an account.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="step2-create-a-project">STEP2: Create a project<a href="#step2-create-a-project" class="hash-link" aria-label="Direct link to STEP2: Create a project" title="Direct link to STEP2: Create a project">​</a></h3><p>After successful login, you will be directed to the project list page. Click the <strong>Create</strong> button in the top right corner to create a new project. Enter the project name and click the <strong>Submit</strong> button to create the project.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="step3-run-the-models">STEP3: Run the models<a href="#step3-run-the-models" class="hash-link" aria-label="Direct link to STEP3: Run the models" title="Direct link to STEP3: Run the models">​</a></h3><p>Go to the <strong>Evaluations</strong> list pag, click the <strong>Create</strong> button, and then choose the parameters.</p><p>For example, to reproduce the evaluation result of baichuan2-13b with the cmmlu dataset, refer to the following:</p><ol><li>Choose the running resource, recommend to select A10<!-- -->*<!-- -->24G<!-- -->*<!-- -->2;</li><li>Select the model: Choose the models you want to reproduce, e.g.: starwhale/llm-leaderboard/baichuan2-13b/atgoiscm(v1、latest);</li><li>Choose the handler: Select the option "src.evaluation:evaluation_results";</li><li>Choose the dataset: Select the option "starwhale/llm-leaderboard/cmmlu/kiwtxza7(v1、latest)";</li><li>Choose the runtime: Select the option "starwhale/llm-leaderboard/llm-leaderboard/ickinf6q(v1、latest)".</li><li>Advanced configuration: Turn off the auto-release switch.</li></ol><p>Click <strong>Submit</strong> to run the model. During the evaluation process, you can click <strong>View Log</strong> on the task tab of the evaluation details page to understand the running status of the evaluation. When the evaluation status is "Successed," you can view the results on the list and details pages.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="step4-compare-the-evaluation-results">STEP4: Compare the evaluation results<a href="#step4-compare-the-evaluation-results" class="hash-link" aria-label="Direct link to STEP4: Compare the evaluation results" title="Direct link to STEP4: Compare the evaluation results">​</a></h3><p>To create a report, go to the <strong>Report</strong> list page and click the <strong>Create</strong> button in the upper right corner.</p><p>Reports provide rich text editing capabilities, and here we mainly introduce how to compare your evaluation results with Starwhale or other evaluation results.</p><ol><li>Input the report title and description;</li><li>Input <strong>/</strong>, select and click the <strong>Panel</strong> option;</li><li>Click the <strong>Add Evaluation</strong> button, select the project, such as "llm-leaderboard", and then to check the evaluations you want to add. Click <strong>Add</strong> to add evaluations to the evaluation list. You can add multiple evaluations that you want to compare across different projects;</li><li>After adding the evaluations, click the <strong>Column Management</strong> settings icon to set the columns in the evaluation list and their display order. When you hover over a column in the evaluation list, you can fix that column or sort it in ascending or descending order;</li><li>You can click the <strong>Add Chart</strong> button and select the chart type, such as Bar Chart, then add Metrics related to accuracy (support for metric fuzzy search). Input a chart title (optional) and click <strong>Submit</strong> to display the data in bar chart format for intuitive analysis.</li><li>Click <strong>Publish to Project</strong> button to publish the report;</li><li>If you want to share the report with others, go to the <strong>Report</strong> list page, turn on the "Share" switch, and people who obtain the report link can view it.</li></ol><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/Blog/reproduce-and-compare-evals.gif" alt="reproduce-and-compare-evals.gif" class="img_ev3q"></p><p>These are the instructions on how to reproduce and compare evaluations using Starwhale. Please leave a private message if you encounter any issues during the using process. You can also visit the <a href="https://starwhale.cn" target="_blank" rel="noopener noreferrer">Starwhale official website</a> for more information. Thank you for your attention and support.</p>]]></content>
        <author>
            <name>Starwhale</name>
        </author>
        <category label="Model Package" term="Model Package"/>
        <category label="Model Evaluaitons" term="Model Evaluaitons"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Run Llama 2-Chat from scratch in 5 minutes]]></title>
        <id>https://doc.starwhale.ai/blog/run-llama2-chat-in-five-minutes</id>
        <link href="https://doc.starwhale.ai/blog/run-llama2-chat-in-five-minutes"/>
        <updated>2023-07-24T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[docusaurus-plugin-content-blog]]></summary>
        <content type="html"><![CDATA[<p>Meta Llama 2, once released captured the attention of the entire world. <a href="https://starwhale.cn/" target="_blank" rel="noopener noreferrer">Starwhale</a> has specially developed the Llama 2-Chat and Llama 2-7b model packages. In just 5 minutes, you can engage in a conversation with Llama 2-Chat from scratch on <a href="https://cloud.starwhale.cn" target="_blank" rel="noopener noreferrer">https://cloud.starwhale.cn</a>.</p><p>In the future, we will also provide model packages for Llama 2-13b and Llama 2-70b. Interested friends, please stay tuned!</p><p>The following will provide a detailed introduction to what is Llama 2, what is Starwhale, and how to use Starwhale to run Llama 2-Chat.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-is-llama-2">What is Llama 2<a href="#what-is-llama-2" class="hash-link" aria-label="Direct link to What is Llama 2" title="Direct link to What is Llama 2">​</a></h2><p>The Llama 2 series models are a set of large language models that utilize optimized autoregressive Transformer architecture. They have undergone pre-training and fine-tuning and come in three parameter versions: 7 billion, 13 billion, and 70 billion. Additionally, Meta has trained a 34 billion parameter version, but it has not been released, and relevant data is mentioned in the research paper.</p><p>Pre-training: Compared to Llama 1, Llama 2's training data has increased by 40%, using 2 trillion tokens for training, and the context length is twice that of Llama 1, reaching 4096. Llama 2 is well-suited for various natural language generation tasks.</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/cmp1-2.png" alt="image" class="img_ev3q"></p><p>Meta compared the results of Llama 2-70b with closed-source models and found that its performance is close to GPT-3.5 on MMLU (Multilingual Multimodal Language Understanding) and GSM8K (German Speech Recognition) tasks. However, there are significant differences in performance on encoding benchmarks.</p><p>Moreover, on almost all benchmarks, Llama 2-70b performs on par with or even better than Google's PaLM-540b model. But there still remains a considerable gap in performance when compared to models like GPT-4 and PaLM-2-L.</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/evaluation.png" alt="image" class="img_ev3q"></p><p>Fine-tuning: Llama 2-Chat is a version of Llama 2 that has been fine-tuned specifically for chat dialogue scenarios. The fine-tuning process involves using SFT (Supervised Fine-Tuning) and RLHF (Reinforcement Learning from Human Feedback) in an iterative optimization to align better with human preferences and improve safety. The fine-tuning data includes publicly available instruction datasets and over one million newly annotated samples. Llama 2-Chat can be used for chat applications similar to virtual assistants. The image below shows the percentage of violations in single-turn and multi-turn conversations. Compared to the baseline, Llama 2-Chat performs particularly well in multi-turn conversations.</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/voliation.png" alt="image" class="img_ev3q"></p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-is-starwhale">What is Starwhale<a href="#what-is-starwhale" class="hash-link" aria-label="Direct link to What is Starwhale" title="Direct link to What is Starwhale">​</a></h2><p>Starwhale is an MLOps platform that offers a comprehensive solution for the entire machine learning operations process. It enables developers and businesses to efficiently and conveniently manage model hosting, execution, evaluation, deployment, and dataset management. Users can choose from three different versions: Standalone, Server, or Cloud, based on their specific requirements. For more detailed information and instructions on using Starwhale, users can refer to the platform's <a href="https://starwhale.cn/docs/" target="_blank" rel="noopener noreferrer">documentation</a>.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-to-use-starwhale-to-run-llama-2-chat">how to use Starwhale to run Llama 2-Chat<a href="#how-to-use-starwhale-to-run-llama-2-chat" class="hash-link" aria-label="Direct link to how to use Starwhale to run Llama 2-Chat" title="Direct link to how to use Starwhale to run Llama 2-Chat">​</a></h2><p>Workflow：Login → Create a project → Run the model → Chat with Llama2</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="1-login"><strong>1. Login</strong><a href="#1-login" class="hash-link" aria-label="Direct link to 1-login" title="Direct link to 1-login">​</a></h3><p>First, you need to log in to the Starwhale platform by clicking on the <a href="https://cloud.starwhale.cn/login?lang=zh" target="_blank" rel="noopener noreferrer">login</a>. If you haven't registered yet, you can click on the <a href="https://cloud.starwhale.cn/signup" target="_blank" rel="noopener noreferrer">sign-up</a> to create an account.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="2-create-a-project"><strong>2. Create a project</strong><a href="#2-create-a-project" class="hash-link" aria-label="Direct link to 2-create-a-project" title="Direct link to 2-create-a-project">​</a></h3><p>After successful login, you will be directed to the project list page. Click on the Create button on the top right corner to create a new project. Enter the project name and click on the Submit button to create the project.</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/project-list.png" alt="image" class="img_ev3q"></p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/project-create.png" alt="image" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="3-run-the-model"><strong>3. Run the model</strong><a href="#3-run-the-model" class="hash-link" aria-label="Direct link to 3-run-the-model" title="Direct link to 3-run-the-model">​</a></h3><p>Go to the job list page and click on the Create task button.</p><p> 1) Choose the running resource, you can select A100 80G1 (recommended) or A10 24G1.
2) Select the model: starwhale/public/llama2-7b-chat/ki72ulaf(latest).
3) Choose the handler: Run the chatbot model, select the default option: evaluation:chatbot.
4) Choose the runtime: Select the default option, built-in.
5) Advanced configuration: Turn on the auto-release switch, where you can set the duration after which the task will be automatically canceled. If you don't set auto-release, you can manually cancel the task after the experiment is completed.</p><p>Click on Submit to run the model.</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/evaluation-create.png" alt="image" class="img_ev3q"></p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="4-view-the-results-and-logs"><strong>4. View the Results and Logs</strong><a href="#4-view-the-results-and-logs" class="hash-link" aria-label="Direct link to 4-view-the-results-and-logs" title="Direct link to 4-view-the-results-and-logs">​</a></h4><p>The job list page allows you to view all the tasks in the project.</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/job-list.png" alt="image" class="img_ev3q"></p><p>Click on the Job ID to enter the task details page, and then click on View Logs to see the logs.</p><p>The total time taken from task submission to model execution is 5 minutes.</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/log.png" alt="image" class="img_ev3q"></p><p>Once the execution is successful, return to the task list and click on the Terminal button to open the chatbox page. You can now start a conversation with Llama 2-Chat on the chatbox page.</p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/job-list.png" alt="image" class="img_ev3q"></p><p><img loading="lazy" src="https://starwhale-examples.oss-cn-beijing.aliyuncs.com/docs/blog/llama2/chatbot.png" alt="image" class="img_ev3q"></p><p>These are the instructions on how to use Starwhale Cloud to run Llama 2-Chat. If you encounter any issues during the process, please feel free to leave a private message. You can also visit the <a href="https://starwhale.cn" target="_blank" rel="noopener noreferrer">Starwhale official website</a> for more information. Thank you for your attention and support.</p>]]></content>
        <author>
            <name>Starwhale</name>
        </author>
        <category label="Model Package" term="Model Package"/>
        <category label="llama2" term="llama2"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is Starwhale?]]></title>
        <id>https://doc.starwhale.ai/blog/intro-starwhale</id>
        <link href="https://doc.starwhale.ai/blog/intro-starwhale"/>
        <updated>2023-07-21T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Starwhale description]]></summary>
        <content type="html"><![CDATA[<p>Starwhale is an MLOps platform that make your model creation, evaluation and publication much eaiser. It aims to create a handy tool for data scientists and machine learning engineers.</p><p>Starwhale helps you:</p><ul><li>Keep track of your training/testing data history including data items and their labels, so that you can easily access them.</li><li>Manage your model packages that you can share across your team.</li><li>Run your models in different environments, either on a Nvidia GPU server or on an embedded device like Cherry Pi.</li><li>Create a online service with interactive Web UI for your models.</li></ul><p>Starwhale is designed to be an open platform. You can create your own plugins to meet your requirements.</p>]]></content>
        <author>
            <name>tianwei</name>
            <uri>https://github.com/tianweidut</uri>
        </author>
        <category label="intro" term="intro"/>
    </entry>
</feed>